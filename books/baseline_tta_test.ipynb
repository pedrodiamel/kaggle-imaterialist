{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from pytvision.transforms import transforms as mtrans\n",
    "from pytvision import visualization as view\n",
    "\n",
    "sys.path.append('../')\n",
    "from torchlib.datasets  import factory\n",
    "from torchlib.datasets  import gdata\n",
    "from torchlib.classifierneuralnet import NeuralNetClassifier\n",
    "from torchlib.datasets.imaterialist import IMaterialistImageDataset\n",
    "\n",
    "from misc import get_transforms_aug, get_transforms_det, get_transforms_hflip, get_transforms_gray, get_transforms_aug2\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fernandez/.datasets\n",
      "../out/netruns\n",
      "imaterialist\n",
      "../out/netruns/exp_baseline_inception_v3_cross_adam_imaterialist_002/models/chk000039.pth.tar\n",
      "/home/fernandez/.datasets/imaterialist/test\n"
     ]
    }
   ],
   "source": [
    "home = os.getenv(\"HOME\")\n",
    "pathname= os.path.join(home, '.datasets')\n",
    "name_dataset='imaterialist'\n",
    "project='../out/netruns'\n",
    "no_cuda=False\n",
    "seed=1\n",
    "gpu=0\n",
    "name='exp_baseline_inception_v3_cross_adam_imaterialist_002'\n",
    "model='chk000039.pth.tar'\n",
    "path_model=os.path.join(project,name,'models',model)\n",
    "batch_size=80\n",
    "workers=80\n",
    "num_input_channels=3\n",
    "pathdata=os.path.join( pathname, name_dataset, 'test' )\n",
    "\n",
    "pathnameout = os.path.join(project, 'predicts')\n",
    "\n",
    "\n",
    "print(pathname)\n",
    "print(project)\n",
    "print(name_dataset)\n",
    "print(path_model)\n",
    "print(pathdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '../out/netruns/exp_baseline_inception_v3_cross_adam_imaterialist_002/models/chk000039.pth.tar'\n",
      "=> loaded checkpoint for inception_v3 arch!\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# neuralnet\n",
    "network = NeuralNetClassifier(\n",
    "    patchproject=project,\n",
    "    nameproject=name,\n",
    "    no_cuda=no_cuda,\n",
    "    seed=seed,\n",
    "    gpu=gpu\n",
    "    )\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# load model\n",
    "if network.load( path_model ) is not True:\n",
    "    assert(False)\n",
    "\n",
    "tta_preprocess = [ \n",
    "    get_transforms_det(network.size_input), \n",
    "    get_transforms_hflip(network.size_input), \n",
    "    #get_transforms_gray(network.size_input),\n",
    "    #get_transforms_aug2(network.size_input),\n",
    "    #get_transforms_aug2(network.size_input),    \n",
    "    ]\n",
    "\n",
    "dataloaders = []\n",
    "for transform in tta_preprocess:    \n",
    "    # test dataset\n",
    "    data = IMaterialistImageDataset(\n",
    "        pathname=pathdata,\n",
    "        ext='jpg',\n",
    "        num_channels=num_input_channels,\n",
    "        transform=transform\n",
    "        )\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=workers )\n",
    "    dataloaders.append(dataloader)\n",
    "\n",
    "data_test = data\n",
    "print(len(dataloaders))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159/159 [01:11<00:00,  2.23it/s]\n",
      "100%|██████████| 159/159 [00:40<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir: ../out/netruns/predicts\n",
      "DONE!!!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random.seed( seed )\n",
    "files = [ f for f in sorted(os.listdir(pathnameout)) if f.split('.')[-1] == 'csv' ]; \n",
    "\n",
    "for i,data in enumerate(dataloaders):\n",
    "    Ids, Yhat = network.predict( data )\n",
    "    df = pd.DataFrame( np.concatenate((Ids, Yhat), axis=1) )\n",
    "    df.to_csv( os.path.join(pathnameout , 'test_{}_dp{}.csv'.format(name, i + len(files) ) ), index=False, encoding='utf-8')        \n",
    "\n",
    "print('dir: {}'.format(pathnameout))\n",
    "print('DONE!!!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Multiclasification systems\n",
    " \n",
    "       +-----+  dp_1\n",
    "     --| cnn |---------+\n",
    "       +-----+         |\n",
    "                       | \n",
    "       +-----+  dp_2   |     +--------+\n",
    "     --| cnn |---------+ ----| Fusion |-----------+\n",
    "       +-----+         |     +--------+\n",
    "                       .        |\n",
    "                       .        SOFT, HARD, TR\n",
    "                       .        Soft: sRp, sRs, sRmx, sRmi, sRmd, sRmv\n",
    "       +-----+  dp_L   |        Hard: hWmv, hRec, hNb  \n",
    "     --| cnn |---------+        Train: tFi, tLop, tMb, tMsvm\n",
    "       +-----+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## On Combining Classifiers\n",
    "# - Combining soft ruler\n",
    "# - https://dspace.cvut.cz/bitstream/handle/10467/9443/1998-On-combining-classifiers.pdf?sequence=1\n",
    "    \n",
    "def product_ruler( dp, P=None ):\n",
    "    \"\"\"\n",
    "    Ecuation. Josef Kittler [7]\n",
    "    https://dspace.cvut.cz/bitstream/handle/10467/9443/1998-On-combining-classifiers.pdf?sequence=1\n",
    "    Soft Product Rule    \n",
    "    P^{(-(R-1))}( w_j )\\prod_iP(w_j|x_i)  = \\max_k P^{(-(R-1))}( w_k ) \\prod_i\n",
    "    P(w_k|x_i) (1)\n",
    "    which under the assumption of equal priors, simplifies to the following:\n",
    "    \\prod_iP(w_j|x_i)  = \\max_k \\prod_i P(w_k|x_i) (2)    \n",
    "    Args:\n",
    "        @dp: []_nxcxl\n",
    "        @P: class prior []_c\n",
    "    \"\"\"    \n",
    "    p = dp.prod(2)\n",
    "    if P is not None:\n",
    "        l = dp.shape[2]\n",
    "        p = P**-(l-1)*p\n",
    "    return p\n",
    "\n",
    "def sum_ruler( dp, P=None ):\n",
    "    \"\"\"\n",
    "    Ecuation. Josef Kittler [11]\n",
    "    https://dspace.cvut.cz/bitstream/handle/10467/9443/1998-On-combining-classifiers.pdf?sequence=1\n",
    "    Soft Sum Ruler\n",
    "    $$(1-R)P( w_j ) + \\sum_iP(w_j|x_i)  = \\max_k [ (1-R)P(w_k) + \\sum_iP(w_k|x_i)]$$\n",
    "    which under the assumption of equal priors simplifies to the following:\n",
    "    $$\\sum_iP(w_j|x_i)  = \\max_k \\sum_iP(w_k|x_i)$$    \n",
    "    Args:\n",
    "        @dp: []_nxcxl\n",
    "    \"\"\"\n",
    "    p = dp.sum(2)\n",
    "    if P is not None:\n",
    "        l = dp.shape[2]\n",
    "        p = (1-l)*P + p\n",
    "    return p\n",
    "\n",
    "def max_ruler( dp, P=None ):\n",
    "    \"\"\"\n",
    "    Ecuation. Josef Kittler [14][15]\n",
    "    https://dspace.cvut.cz/bitstream/handle/10467/9443/1998-On-combining-classifiers.pdf?sequence=1\n",
    "    Soft Max Ruler\n",
    "    Args:\n",
    "        @dp: []_nxcxl\n",
    "    \"\"\"\n",
    "    p = dp.max(2)\n",
    "    if P is not None:\n",
    "        l = dp.shape[2]\n",
    "        p = (1-l)*P + l*p\n",
    "    return p\n",
    "\n",
    "def min_ruler( dp, P=None ):\n",
    "    \"\"\"\n",
    "    Ecuation. Josef Kittler [16]\n",
    "    https://dspace.cvut.cz/bitstream/handle/10467/9443/1998-On-combining-classifiers.pdf?sequence=1\n",
    "    Soft Min Ruler\n",
    "    Args:\n",
    "        @dp: []_nxcxl\n",
    "    \"\"\"\n",
    "    p = dp.min(2)\n",
    "    if P is not None:\n",
    "        l = dp.shape[2]\n",
    "        p = P**-(l-1)*p\n",
    "        p = (1-l)*P + l*p\n",
    "    return p\n",
    "\n",
    "\n",
    "def majority_ruler( dp  ):\n",
    "    \"\"\"\n",
    "    Ecuation. Josef Kittler [20]\n",
    "    https://dspace.cvut.cz/bitstream/handle/10467/9443/1998-On-combining-classifiers.pdf?sequence=1\n",
    "    Soft Majority Vote Rule\n",
    "    Args:\n",
    "        @dp: []_nxcxl\n",
    "    \"\"\"\n",
    "    n,c,l = dp.shape\n",
    "    p = np.argmax(dp,axis=1)\n",
    "    \n",
    "    dki = np.zeros((n,c))\n",
    "    for i in range(n):\n",
    "        tup = p[i,:]\n",
    "        for j in range(c):\n",
    "            dki[i,j] = np.sum( tup == j )\n",
    "        \n",
    "    p=dki\n",
    "    return p\n",
    "\n",
    "\n",
    "def mean_ruler( dp ):\n",
    "    \"\"\"\n",
    "    Ecuation. Josef Kittler [18]\n",
    "    https://dspace.cvut.cz/bitstream/handle/10467/9443/1998-On-combining-classifiers.pdf?sequence=1\n",
    "    Soft Median Ruler\n",
    "    Args:\n",
    "        @dp: []_nxcxl\n",
    "    \"\"\"\n",
    "    p = dp.mean(2)\n",
    "    return p\n",
    "    \n",
    "\n",
    "    \n",
    "# # test\n",
    "# #[n,c,l]\n",
    "# #dp = np.random.rand(10,4,3 )\n",
    "# #P = np.array([0.1,0.1,0.1,0.7])\n",
    "# dp = np.array( [[[0.2,0,0,0],[0.8,1.0,1.0,1.0]],[[0.3,0.6,0.9,0.5],[0.7,0.4,0.1,0.5]]] )\n",
    "# P = np.array([0.7,0.3])\n",
    "# print(dp.shape)\n",
    "# #print(dp[:,:,0])\n",
    "\n",
    "# func = [product_ruler, sum_ruler, max_ruler, min_ruler, majority_ruler, mean_ruler]\n",
    "# for f in func:\n",
    "#     p = f(dp)\n",
    "#     print( p.argmax(1) )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_exp_baseline_inception_v3_cross_adam_imaterialist_002_dp0.csv', 'test_exp_baseline_inception_v3_cross_adam_imaterialist_002_dp1.csv']\n",
      "(12704, 128, 2)\n"
     ]
    }
   ],
   "source": [
    "files = [ f for f in sorted(os.listdir(pathnameout)) if f.split('.')[-1] == 'csv' ]; \n",
    "print(files)\n",
    "\n",
    "l = len(files)\n",
    "dp =[]; ids=[]\n",
    "for f in files:  \n",
    "    mdata = pd.read_csv( os.path.join(pathnameout , f )  )\n",
    "    dpdata = mdata.as_matrix()\n",
    "    ids.append(dpdata[:,0])    \n",
    "    dp.append( dpdata[:,1:] )\n",
    "    \n",
    "dp = np.array(dp).transpose((1,2,0))\n",
    "ids = np.array(ids)\n",
    "\n",
    "assert( not (ids[0,:]-ids[:1,:]).sum() )\n",
    "print(dp.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12704, 128, 2)\n",
      "(12704, 128)\n",
      "(12704,)\n"
     ]
    }
   ],
   "source": [
    "Id = ids[0,:]\n",
    "p = mean_ruler(dp)\n",
    "pred = np.argmax(p, axis=1)\n",
    "\n",
    "print(dp.shape)\n",
    "print(p.shape)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 52, 125,  52,  76,  52, 127,  71,  23,  23,  52,  76,  52,  67,\n",
       "        76,   4,   8, 125,  79,  76,  26,  59,  76, 125,  95,  76,  23,\n",
       "        76,   3,  47,  57,  76,  40,  76, 103,  78, 106,  76,  49,  52,\n",
       "        43,  76,  13,  52,  71,  76,  59,  76,  52,  52,  76,  76,  76,\n",
       "        59,  76, 103,  76,  76,  79,  87, 125,  52,  76,  76,  80,  95,\n",
       "        95,  76, 125,  76,  76,  93,  52,  43, 125,  59,  76,  23, 119,\n",
       "       121,  76,  76,  76,  76,  64,  95,  18,  76,  23,  76,  76,  23,\n",
       "        76,  23,  38,  52,  68,  59,  76,  76,  76])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6309\n",
      "{'1': 0, '10': 1, '100': 2, '101': 3, '102': 4, '103': 5, '104': 6, '105': 7, '106': 8, '107': 9, '108': 10, '109': 11, '11': 12, '110': 13, '111': 14, '112': 15, '113': 16, '114': 17, '115': 18, '116': 19, '117': 20, '118': 21, '119': 22, '12': 23, '120': 24, '121': 25, '122': 26, '123': 27, '124': 28, '125': 29, '126': 30, '127': 31, '128': 32, '13': 33, '14': 34, '15': 35, '16': 36, '17': 37, '18': 38, '19': 39, '2': 40, '20': 41, '21': 42, '22': 43, '23': 44, '24': 45, '25': 46, '26': 47, '27': 48, '28': 49, '29': 50, '3': 51, '30': 52, '31': 53, '32': 54, '33': 55, '34': 56, '35': 57, '36': 58, '37': 59, '38': 60, '39': 61, '4': 62, '40': 63, '41': 64, '42': 65, '43': 66, '44': 67, '45': 68, '46': 69, '47': 70, '48': 71, '49': 72, '5': 73, '50': 74, '51': 75, '52': 76, '53': 77, '54': 78, '55': 79, '56': 80, '57': 81, '58': 82, '59': 83, '6': 84, '60': 85, '61': 86, '62': 87, '63': 88, '64': 89, '65': 90, '66': 91, '67': 92, '68': 93, '69': 94, '7': 95, '70': 96, '71': 97, '72': 98, '73': 99, '74': 100, '75': 101, '76': 102, '77': 103, '78': 104, '79': 105, '8': 106, '80': 107, '81': 108, '82': 109, '83': 110, '84': 111, '85': 112, '86': 113, '87': 114, '88': 115, '89': 116, '9': 117, '90': 118, '91': 119, '92': 120, '93': 121, '94': 122, '95': 123, '96': 124, '97': 125, '98': 126, '99': 127}\n",
      "['1', '10', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '11', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '12', '120', '121', '122', '123', '124', '125', '126', '127', '128', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '7', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '8', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '9', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99']\n"
     ]
    }
   ],
   "source": [
    "data_val=factory.FactoryDataset.factory(\n",
    "            pathname=pathname, \n",
    "            name=name_dataset, \n",
    "            subset=factory.validation, \n",
    "            download=True )\n",
    "\n",
    "print(len(data_val))\n",
    "print(data_val.class_to_idx)\n",
    "print(data_val.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  predicted\n",
       "0   1         30\n",
       "1   2         52\n",
       "2   3         91\n",
       "3   4         54\n",
       "4   5        126"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "submission_filepath = '../submission.csv'\n",
    "submission = pd.read_csv('~/.kaggle/competitions/imaterialist-challenge-furniture-2018/sample_submission_randomlabel.csv')\n",
    "\n",
    "TIds = np.array([ int(data_test.getId( int(i) )) for i in Id ])\n",
    "TPred = np.array( [ int(data_val.classes[c]) for c in pred  ] )\n",
    "submission.loc[TIds-1, 'predicted'] = TPred\n",
    "submission.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVE!!!\n"
     ]
    }
   ],
   "source": [
    "submission.to_csv(submission_filepath, index=False, encoding='utf-8')\n",
    "print('SAVE!!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
