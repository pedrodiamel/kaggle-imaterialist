{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=6, micro=5, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from pytvision.transforms import transforms as mtrans\n",
    "from pytvision import visualization as view\n",
    "\n",
    "sys.path.append('../')\n",
    "from torchlib.datasets  import factory\n",
    "from torchlib.datasets  import gdata\n",
    "from torchlib.neuralnet import NeuralNet\n",
    "from torchlib.datasets.imaterialist import IMaterialistImageDataset\n",
    "\n",
    "from misc import get_transforms_aug, get_transforms_det, get_transforms_hflip, get_transforms_gray, get_transforms_aug2\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fernandez/.datasets\n",
      "../out/netruns\n",
      "imaterialist\n",
      "../out/netruns/exp_net_baseline_resnet152_imaterialist_001/models/chk000050.pth.tar\n"
     ]
    }
   ],
   "source": [
    "home = os.getenv(\"HOME\")\n",
    "pathname= os.path.join(home, '.datasets')\n",
    "name_dataset='imaterialist'\n",
    "project='../out/netruns'\n",
    "no_cuda=False\n",
    "seed=1\n",
    "gpu=1\n",
    "name='exp_net_baseline_resnet152_imaterialist_001'\n",
    "model= 'chk000050.pth.tar' #'model_best.pth.tar'\n",
    "path_model=os.path.join(project,name,'models',model)\n",
    "batch_size=120\n",
    "workers=80\n",
    "num_input_channels=3\n",
    "pathnameout = os.path.join(project, 'validation')\n",
    "\n",
    "print(pathname)\n",
    "print(project)\n",
    "print(name_dataset)\n",
    "print(path_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '../out/netruns/exp_net_baseline_resnet152_imaterialist_001/models/chk000050.pth.tar'\n",
      "=> loaded checkpoint for resnet152 arch!\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# neuralnet\n",
    "network = NeuralNet(\n",
    "    patchproject=project,\n",
    "    nameproject=name,\n",
    "    no_cuda=no_cuda,\n",
    "    seed=seed,\n",
    "    gpu=gpu\n",
    "    )\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# load model\n",
    "if network.load( path_model ) is not True:\n",
    "    assert(False)\n",
    "\n",
    "tta_preprocess = [ \n",
    "    get_transforms_det(network.size_input), \n",
    "    get_transforms_hflip(network.size_input), \n",
    "    #get_transforms_gray(network.size_input),\n",
    "    #get_transforms_aug(network.size_input),\n",
    "    #get_transforms_aug2(network.size_input)\n",
    "    ]\n",
    "\n",
    "dataloaders = []\n",
    "for transform in tta_preprocess:    \n",
    "    # test dataset\n",
    "    data = gdata.Dataset(\n",
    "        data=factory.FactoryDataset.factory(\n",
    "            pathname=pathname, \n",
    "            name=name_dataset, \n",
    "            subset=factory.validation, \n",
    "            download=True ),\n",
    "        num_channels=num_input_channels,\n",
    "        transform=transform\n",
    "        )\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=workers )\n",
    "    dataloaders.append(dataloader)\n",
    "\n",
    "print(len(dataloaders))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:33<00:00,  1.59it/s]\n",
      "100%|██████████| 53/53 [00:32<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir: ../out/netruns/validation\n",
      "DONE!!!\n"
     ]
    }
   ],
   "source": [
    "random.seed( seed )\n",
    "files = [ f for f in sorted(os.listdir(pathnameout)) if f.split('.')[-1] == 'csv' ]; \n",
    "\n",
    "for i,data in enumerate(dataloaders):\n",
    "    Yhat, Y = network.test( data )\n",
    "    df = pd.DataFrame( np.concatenate((Y, Yhat), axis=1) )\n",
    "    df.to_csv( os.path.join(pathnameout , 'val_{}_dp{}.csv'.format(name, i + len(files) )  ), index=False, encoding='utf-8')        \n",
    "\n",
    "print('dir: {}'.format(pathnameout))\n",
    "print('DONE!!!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Multiclasification systems\n",
    " \n",
    "       +-----+  dp_1\n",
    "     --| cnn |---------+\n",
    "       +-----+         |\n",
    "                       | \n",
    "       +-----+  dp_2   |     +--------+\n",
    "     --| cnn |---------+ ----| Fusion |-----------+\n",
    "       +-----+         |     +--------+\n",
    "                       .        |\n",
    "                       .        SOFT, HARD, TR\n",
    "                       .        Soft: sRp, sRs, sRmx, sRmi, sRmd, sRmv\n",
    "       +-----+  dp_L   |        Hard: hWmv, hRec, hNb  \n",
    "     --| cnn |---------+        Train: tFi, tLop, tMb, tMsvm\n",
    "       +-----+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## On Combining Classifiers\n",
    "# - Combining soft ruler\n",
    "# - https://dspace.cvut.cz/bitstream/handle/10467/9443/1998-On-combining-classifiers.pdf?sequence=1\n",
    "    \n",
    "def product_ruler( dp, P=None ):\n",
    "    \"\"\"\n",
    "    Ecuation. Josef Kittler [7]\n",
    "    https://dspace.cvut.cz/bitstream/handle/10467/9443/1998-On-combining-classifiers.pdf?sequence=1\n",
    "    Soft Product Rule    \n",
    "    P^{(-(R-1))}( w_j )\\prod_iP(w_j|x_i)  = \\max_k P^{(-(R-1))}( w_k ) \\prod_i\n",
    "    P(w_k|x_i) (1)\n",
    "    which under the assumption of equal priors, simplifies to the following:\n",
    "    \\prod_iP(w_j|x_i)  = \\max_k \\prod_i P(w_k|x_i) (2)    \n",
    "    Args:\n",
    "        @dp: []_nxcxl\n",
    "        @P: class prior []_c\n",
    "    \"\"\"    \n",
    "    p = dp.prod(2)\n",
    "    if P is not None:\n",
    "        l = dp.shape[2]\n",
    "        p = P**-(l-1)*p\n",
    "    return p\n",
    "\n",
    "def sum_ruler( dp, P=None ):\n",
    "    \"\"\"\n",
    "    Ecuation. Josef Kittler [11]\n",
    "    https://dspace.cvut.cz/bitstream/handle/10467/9443/1998-On-combining-classifiers.pdf?sequence=1\n",
    "    Soft Sum Ruler\n",
    "    $$(1-R)P( w_j ) + \\sum_iP(w_j|x_i)  = \\max_k [ (1-R)P(w_k) + \\sum_iP(w_k|x_i)]$$\n",
    "    which under the assumption of equal priors simplifies to the following:\n",
    "    $$\\sum_iP(w_j|x_i)  = \\max_k \\sum_iP(w_k|x_i)$$    \n",
    "    Args:\n",
    "        @dp: []_nxcxl\n",
    "    \"\"\"\n",
    "    p = dp.sum(2)\n",
    "    if P is not None:\n",
    "        l = dp.shape[2]\n",
    "        p = (1-l)*P + p\n",
    "    return p\n",
    "\n",
    "def max_ruler( dp, P=None ):\n",
    "    \"\"\"\n",
    "    Ecuation. Josef Kittler [14][15]\n",
    "    https://dspace.cvut.cz/bitstream/handle/10467/9443/1998-On-combining-classifiers.pdf?sequence=1\n",
    "    Soft Max Ruler\n",
    "    Args:\n",
    "        @dp: []_nxcxl\n",
    "    \"\"\"\n",
    "    p = dp.max(2)\n",
    "    if P is not None:\n",
    "        l = dp.shape[2]\n",
    "        p = (1-l)*P + l*p\n",
    "    return p\n",
    "\n",
    "def min_ruler( dp, P=None ):\n",
    "    \"\"\"\n",
    "    Ecuation. Josef Kittler [16]\n",
    "    https://dspace.cvut.cz/bitstream/handle/10467/9443/1998-On-combining-classifiers.pdf?sequence=1\n",
    "    Soft Min Ruler\n",
    "    Args:\n",
    "        @dp: []_nxcxl\n",
    "    \"\"\"\n",
    "    p = dp.min(2)\n",
    "    if P is not None:\n",
    "        l = dp.shape[2]\n",
    "        p = P**-(l-1)*p\n",
    "        p = (1-l)*P + l*p\n",
    "    return p\n",
    "\n",
    "\n",
    "def majority_ruler( dp  ):\n",
    "    \"\"\"\n",
    "    Ecuation. Josef Kittler [20]\n",
    "    https://dspace.cvut.cz/bitstream/handle/10467/9443/1998-On-combining-classifiers.pdf?sequence=1\n",
    "    Soft Majority Vote Rule\n",
    "    Args:\n",
    "        @dp: []_nxcxl\n",
    "    \"\"\"\n",
    "    n,c,l = dp.shape\n",
    "    p = np.argmax(dp,axis=1)\n",
    "    \n",
    "    dki = np.zeros((n,c))\n",
    "    for i in range(n):\n",
    "        tup = p[i,:]\n",
    "        for j in range(c):\n",
    "            dki[i,j] = np.sum( tup == j )\n",
    "        \n",
    "    p=dki\n",
    "    return p\n",
    "\n",
    "\n",
    "def mean_ruler( dp ):\n",
    "    \"\"\"\n",
    "    Ecuation. Josef Kittler [18]\n",
    "    https://dspace.cvut.cz/bitstream/handle/10467/9443/1998-On-combining-classifiers.pdf?sequence=1\n",
    "    Soft Median Ruler\n",
    "    Args:\n",
    "        @dp: []_nxcxl\n",
    "    \"\"\"\n",
    "    p = dp.mean(2)\n",
    "    return p\n",
    "    \n",
    "\n",
    "    \n",
    "# # test\n",
    "# #[n,c,l]\n",
    "# #dp = np.random.rand(10,4,3 )\n",
    "# #P = np.array([0.1,0.1,0.1,0.7])\n",
    "# dp = np.array( [[[0.2,0,0,0],[0.8,1.0,1.0,1.0]],[[0.3,0.6,0.9,0.5],[0.7,0.4,0.1,0.5]]] )\n",
    "# P = np.array([0.7,0.3])\n",
    "# print(dp.shape)\n",
    "# #print(dp[:,:,0])\n",
    "\n",
    "# func = [product_ruler, sum_ruler, max_ruler, min_ruler, majority_ruler, mean_ruler]\n",
    "# for f in func:\n",
    "#     p = f(dp)\n",
    "#     print( p.argmax(1) )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['val_exp_net_baseline_nasnetalarge_imaterialist_002_dp0.csv'\n",
      " 'val_exp_net_baseline_nasnetalarge_imaterialist_002_dp1.csv'\n",
      " 'val_exp_net_baseline_nasnetalarge_imaterialist_002_dp2.csv'\n",
      " 'val_exp_net_baseline_nasnetalarge_imaterialist_002_dp3.csv'\n",
      " 'val_exp_net_baseline_resnet152_imaterialist_001_dp6.csv'\n",
      " 'val_exp_net_baseline_resnet152_imaterialist_001_dp7.csv']\n",
      "(6309, 128, 6)\n"
     ]
    }
   ],
   "source": [
    "files = np.array([ f for f in sorted(os.listdir(pathnameout)) if f.split('.')[-1] == 'csv' ]); \n",
    "#idx = np.array([0,1,2,3,6,7], dtype=int) #2,3,7\n",
    "# files = files[:-2]\n",
    "print(files)\n",
    "\n",
    "l = len(files)\n",
    "dp =[]; ys=[]\n",
    "for f in files:  \n",
    "    mdata = pd.read_csv( os.path.join(pathnameout , f )  )\n",
    "    dpdata = mdata.as_matrix()\n",
    "    ys.append(dpdata[:,0])    \n",
    "    dp.append( dpdata[:,1:] )\n",
    "    \n",
    "dp = np.array(dp).transpose((1,2,0))\n",
    "ys = np.array(ys)\n",
    "\n",
    "assert( not (ys[0,:]-ys[:1,:]).sum() )\n",
    "print(dp.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Individual: \n",
      "0 val_exp_net_baseline_nasnetalarge_imaterialist_002_dp0.csv\tmodel_0:\t0.8464098906324299\n",
      "1 val_exp_net_baseline_nasnetalarge_imaterialist_002_dp1.csv\tmodel_1:\t0.8505309874782058\n",
      "2 val_exp_net_baseline_nasnetalarge_imaterialist_002_dp2.csv\tmodel_2:\t0.8441908384847044\n",
      "3 val_exp_net_baseline_nasnetalarge_imaterialist_002_dp3.csv\tmodel_3:\t0.8429228086860041\n",
      "4 val_exp_net_baseline_resnet152_imaterialist_001_dp6.csv\tmodel_4:\t0.8167696940878111\n",
      "5 val_exp_net_baseline_resnet152_imaterialist_001_dp7.csv\tmodel_5:\t0.8202567760342369\n",
      "\n",
      "Multiclasification: \n",
      "product_ruler:\t0.8678078934854969\n",
      "sum_ruler:\t0.8663813599619591\n",
      "max_ruler:\t0.8579806625455698\n",
      "min_ruler:\t0.8614677444919956\n",
      "majority_ruler:\t0.8625772705658583\n",
      "mean_ruler:\t0.8663813599619591\n"
     ]
    }
   ],
   "source": [
    "y = ys[0,:]\n",
    "\n",
    "# individual result\n",
    "print('\\nIndividual: ')\n",
    "p = np.argmax(dp,axis=1)\n",
    "for i in range(p.shape[1]):\n",
    "    pred = p[:,i]\n",
    "    acc = (pred==y).astype(float).sum()/len(y)\n",
    "    print(i, '{}\\tmodel_{}:\\t{}'.format(files[i], i, acc) )\n",
    "\n",
    "# multiclasification result\n",
    "print('\\nMulticlasification: ')\n",
    "func = [product_ruler, sum_ruler, max_ruler, min_ruler, majority_ruler, mean_ruler]\n",
    "for f in func:\n",
    "    p = f(dp)\n",
    "    pred = np.argmax(p, axis=1)\n",
    "    acc = (pred==y).astype(float).sum()/len(y)\n",
    "    print('{}:\\t{}'.format(f.__name__, acc))\n",
    "\n",
    "\n",
    "# p = max_ruler(dp)\n",
    "# pred = np.argmax(p, axis=1)\n",
    "# print(y[:10], y.sum() )\n",
    "# print(pred[:10], pred.sum() )\n",
    "# acc = (pred==y).sum()/len(y)\n",
    "# print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
